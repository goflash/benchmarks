#!/usr/bin/env bash
set -euo pipefail

# Run ApacheBench or wrk against all servers with identical params and collect stats
# Usage: ./scripts/speedtest/bin/run -n 300000000 -c 256 -k [--stop] [--tool wrk|ab] [--batches 10] [--retries 10]

cd "$(dirname "$0")/.."

# Total target requests per framework/scenario (split into batches)
N=100000000
# Concurrency (ab: -c, wrk: -c)
C=128
KEEP=""
SHUTDOWN_AFTER=false
READ_TIMEOUT=60
TOOL=${TOOL:-wrk} # wrk | ab
# wrk defaults
WRK_THREADS_DEFAULT=$(getconf _NPROCESSORS_ONLN 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo 4)
WRK_THREADS=${WRK_THREADS:-$WRK_THREADS_DEFAULT}
WRK_TIMEOUT=${WRK_TIMEOUT:-10s}
# Batching and retries
BATCHES=${BATCHES:-10}
MAX_RETRIES=${MAX_RETRIES:-10}
# Optional sleep between batch retries (seconds)
RETRY_SLEEP=${RETRY_SLEEP:-2}
# Optional sleep between successful batches (seconds)
BATCH_PAUSE=${BATCH_PAUSE:-30}

# Error tolerance defaults (can be overridden via env)
ALLOW_SOCKET_ERRORS=${ALLOW_SOCKET_ERRORS:-1000}
ALLOW_NON2XX=${ALLOW_NON2XX:-0}
ALLOW_AB_FAILED=${ALLOW_AB_FAILED:-1000}

# Scenarios where non-2xx is expected and should not fail batches (space-separated)
EXPECT_NON2XX_SCENARIOS=${EXPECT_NON2XX_SCENARIOS:-"regex_bad"}

# Extra options passed to ab; default tolerate socket recv errors (-r)
AB_OPTS=${AB_OPTS:-"-r"}
# macOS: ensure -r is present to avoid aborting on occasional RSTs
if [[ "$(uname -s)" == "Darwin" ]] && [[ " $AB_OPTS " != *" -r "* ]]; then
  AB_OPTS="$AB_OPTS -r"
fi

# Scenarios and their paths
SCENARIOS=(
  "simple:GET:/ping"
  "middleware:GET:/mw/ping"
  "context:GET:/mw/ctx"
  "json:POST:/json"
  "groups:GET:/api/v1/group/ping"
  "param:GET:/param/abc123"
  "wildcard:GET:/wild/some/long/path/here"
  "deepgroups:GET:/g1/g2/g3/g4/g5/g6/g7/g8/g9/g10/ping"
  "mw10:GET:/mw10/ping"
)

FRAMEWORKS=(
  "flash:http://127.0.0.1:18080"
  "gin:http://127.0.0.1:18081"
  "gofiber:http://127.0.0.1:18082"
)

# Cooldown (seconds) before each run
COOLDOWN=10

# parse args
while [[ $# -gt 0 ]]; do
  case "$1" in
    -n) N="$2"; shift 2 ;;
    -c) C="$2"; shift 2 ;;
    -k) KEEP="-k"; shift ;;
    --stop) SHUTDOWN_AFTER=true; shift ;;
    --tool) TOOL="$2"; shift 2 ;;
    --batches) BATCHES="$2"; shift 2 ;;
    --retries) MAX_RETRIES="$2"; shift 2 ;;
    *) echo "Unknown option: $1"; exit 1 ;;
  esac
done

mkdir -p results/raw results/parts

# Raise file-descriptor limit if too low (best effort for this process)
current_nofile=$(ulimit -n || echo 256)
if [[ "$current_nofile" =~ ^[0-9]+$ ]]; then
  if (( current_nofile < 65536 )); then ulimit -n 65536 || true; fi
fi

# Ensure servers are running
if ! curl -fsS http://127.0.0.1:18080/ping >/dev/null 2>&1; then
  echo "Starting servers..."
  ./bin/start || true
fi

# wait until URL is healthy or timeout
wait_healthy() {
  local url="$1"; local tries=100
  until curl -fsS "$url" >/dev/null 2>&1; do
    ((tries--)) || { echo "Timeout waiting for $url" >&2; return 1; }
    sleep 0.1
  done
}

# quick warm-up to reduce connection resets at start
warmup() {
  local method="$1"; local url="$2"
  if [[ "$TOOL" == "wrk" ]]; then
    if [[ "$method" == "POST" ]]; then
      wrk -t "$WRK_THREADS" -c 50 -d 2s --latency --timeout "$WRK_TIMEOUT" -s wrk/post.lua "$url" >/dev/null 2>&1 || true
    else
      wrk -t "$WRK_THREADS" -c 50 -d 2s --latency --timeout "$WRK_TIMEOUT" "$url" >/dev/null 2>&1 || true
    fi
  else
    case "$method" in
      GET)  ab $AB_OPTS -n 300 -c 50 $KEEP "$url" >/dev/null 2>&1 || true ;;
      POST) ab $AB_OPTS -n 300 -c 50 $KEEP -p body.json -T application/json "$url" >/dev/null 2>&1 || true ;;
    esac
  fi
}

# --- Tool runners (batch) ---
run_ab_batch() {
  local name="$1"; local method="$2"; local url="$3"; local scen="$4"; local n="$5"; local batch="$6"
  local out="results/raw/${name}_${scen}_n${n}_c${C}${KEEP:+_keep}_b${batch}.txt"
  echo "Running ab for $name [$scen] batch $batch/$BATCHES: -n $n -c $C $KEEP $url"
  if [[ "$method" == "POST" ]]; then
    ab $AB_OPTS -q $KEEP -n "$n" -c "$C" -s "$READ_TIMEOUT" -p body.json -T application/json "$url" | tee "$out" || true
  else
    ab $AB_OPTS -q $KEEP -n "$n" -c "$C" -s "$READ_TIMEOUT" "$url" | tee "$out" || true
  fi
}

run_wrk_batch() {
  local name="$1"; local method="$2"; local url="$3"; local scen="$4"; local n="$5"; local batch="$6"
  # Pilot run to estimate RPS
  local pilot_out; pilot_out=$(mktemp)
  if [[ "$method" == "POST" ]]; then
    wrk -t "$WRK_THREADS" -c "$C" -d 3s --latency --timeout "$WRK_TIMEOUT" -s wrk/post.lua "$url" | tee "$pilot_out" >/dev/null || true
  else
    wrk -t "$WRK_THREADS" -c "$C" -d 3s --latency --timeout "$WRK_TIMEOUT" "$url" | tee "$pilot_out" >/dev/null || true
  fi
  local rps; rps=$(grep -E "Requests/sec" "$pilot_out" | awk '{print $2}' || true)
  rm -f "$pilot_out"
  if [[ -z "${rps:-}" ]]; then rps=10000; fi
  # Duration to reach ~n requests
  local dur; dur=$(awk -v n="$n" -v rps="$rps" 'BEGIN{d = (n/rps); printf "%d", (d==int(d)? d : int(d)+1)}')
  if (( dur < 5 )); then dur=5; fi
  local out="results/raw/${name}_${scen}_n${n}_c${C}${KEEP:+_keep}_wrk_b${batch}.txt"
  echo "Running wrk for $name [$scen] batch $batch/$BATCHES: ~n=$n (est rps=$rps) -> duration ${dur}s, -t $WRK_THREADS -c $C $url"
  if [[ "$method" == "POST" ]]; then
    wrk -t "$WRK_THREADS" -c "$C" -d "${dur}s" --latency --timeout "$WRK_TIMEOUT" -s wrk/post.lua "$url" | tee "$out" || true
  else
    wrk -t "$WRK_THREADS" -c "$C" -d "${dur}s" --latency --timeout "$WRK_TIMEOUT" "$url" | tee "$out" || true
  fi
}

# --- Parsers ---
parse_ab_vals() { # echoes CSV: rps,avg,p50,p90,p99,kbps
  local file="$1"
  awk -v OFS="," '
    /Requests per second/ { rps=$4 }
    /Time per request:[[:space:]]+[0-9.]+[[:space:]]+\[ms\] \(mean\)/ { avg=$4 }
    /^[[:space:]]*50%/ { p50=$2 }
    /^[[:space:]]*90%/ { p90=$2 }
    /^[[:space:]]*99%/ { p99=$2 }
    /Transfer rate/ { kbps=$3 }
    END { printf "%s,%s,%s,%s,%s,%s", rps, avg, p50, p90, p99, kbps }
  ' "$file"
}

parse_wrk_vals() { # echoes CSV: rps,avg,p50,p90,p99,kbps
  local file="$1"
  awk -v OFS="," '
    function to_ms(s){ v=s; gsub(/[^0-9.]/,"",v); u=s; gsub(/[0-9.]/,"",u); if(u=="us"||u=="US") return v/1000; else if(u=="ms"||u=="MS"||u=="") return v; else if(u=="s"||u=="S") return v*1000; else return v }
    function to_kbps(s){ n=s; gsub(/[^0-9.]/,"",n); u=s; gsub(/[0-9.]/,"",u); if(u=="B"||u=="b") return n/1024; else if(u=="KB"||u=="K"||u=="kB"||u=="k") return n; else if(u=="MB"||u=="M"||u=="mB"||u=="m") return n*1024; else if(u=="GB"||u=="G"||u=="gB"||u=="g") return n*1024*1024; else return n }
    /Requests\/sec/ { rps=$2 }
    /^[[:space:]]*Latency[[:space:]]/ && !gotlat { avg=to_ms($2); gotlat=1 }
    /^[[:space:]]*50(\.0+)?%/ { p50=to_ms($2) }
    /^[[:space:]]*90(\.0+)?%/ { p90=to_ms($2) }
    /^[[:space:]]*99(\.0+)?%/ { p99=to_ms($2) }
    /^[[:space:]]*99\.[0-9]+%/ { p999=to_ms($2) }
    /Transfer\/sec/ { kbps=to_kbps($2) }
    END { if(!p99 && p999) p99=p999; printf "%s,%s,%s,%s,%s,%s", rps, avg, p50, p90, p99, kbps }
  ' "$file"
}

check_ab_ok() {
  local file="$1"
  local failed=0 non2xx=0
  read -r failed non2xx < <(awk '
    /^Failed requests:/ {f=$3+0}
    /^Non-2xx responses:/ {n=$3+0}
    END { if(f=="") f=0; if(n=="") n=0; printf "%d %d", f, n }
  ' "$file")
  local allow_failed="${ALLOW_AB_FAILED:-0}"
  local allow_non2xx="${ALLOW_NON2XX:-0}"
  if (( failed > allow_failed || non2xx > allow_non2xx )); then return 1; else return 0; fi
}

check_wrk_ok() {
  local file="$1"
  local se=0 non2xx=0
  read -r se non2xx < <(awk -F '[:, ]+' '
    /Socket errors:/ { c=$4+0; r=$6+0; w=$8+0; t=$10+0; se=c+r+w+t }
    /Non-2xx/ { for(i=1;i<=NF;i++) if($i ~ /^[0-9]+$/) nz=$i }
    END { if(se=="") se=0; if(nz=="") nz=0; printf "%d %d", se, nz }
  ' "$file")
  local allow_se="${ALLOW_SOCKET_ERRORS:-0}"
  local allow_non2xx="${ALLOW_NON2XX:-0}"
  if (( se > allow_se || non2xx > allow_non2xx )); then return 1; else return 0; fi
}

# Combined CSV
COMBINED="results/summary_all_n${N}_c${C}${KEEP:+_keep}.csv"
echo "scenario,framework,requests_per_sec,avg_ms,p50_ms,p90_ms,p99_ms,transfer_kbps" > "$COMBINED"

# Verify health for all servers first
for fwEntry in "${FRAMEWORKS[@]}"; do
  base="${fwEntry#*:}"
  wait_healthy "${base}/ping" || true
done

for scenEntry in "${SCENARIOS[@]}"; do
  scen="${scenEntry%%:*}"
  rest="${scenEntry#*:}"
  method="${rest%%:*}"
  path="${rest#*:}"

  # Whether to allow non-2xx for this scenario
  allow_non2xx_this_scen=0
  for s in $EXPECT_NON2XX_SCENARIOS; do
    if [[ "$scen" == "$s" ]]; then allow_non2xx_this_scen=1; break; fi
  done

  SCNCSV="results/summary_${scen}_n${N}_c${C}${KEEP:+_keep}.csv"
  echo "scenario,framework,requests_per_sec,avg_ms,p50_ms,p90_ms,p99_ms,transfer_kbps" > "$SCNCSV"
  PARTS="results/parts/summary_${scen}_n${N}_c${C}${KEEP:+_keep}_parts.csv"
  echo "scenario,batch,framework,requests_per_sec,avg_ms,p50_ms,p90_ms,p99_ms,transfer_kbps" > "$PARTS"

  for fwEntry in "${FRAMEWORKS[@]}"; do
    name="${fwEntry%%:*}"
    base="${fwEntry#*:}"
    url="${base}${path}"
    warmup "$method" "$url"
    echo "Cooldown ${COOLDOWN}s before first batch for ${name} [${scen}]..."; sleep "$COOLDOWN"

    # Batch target size (~ceil(N/BATCHES))
    batchN=$(awk -v n="$N" -v b="$BATCHES" 'BEGIN{printf "%d", int((n + b - 1)/b)}')
    tmpStats=$(mktemp)
    successCount=0

    for ((batch=1; batch<=BATCHES; batch++)); do
      # Short per-batch warmup to stabilize connections
      warmup "$method" "$url"
      # Retry loop
      ok=false
      for ((attempt=1; attempt<=MAX_RETRIES; attempt++)); do
        if [[ "$TOOL" == "wrk" ]]; then
          command -v wrk >/dev/null 2>&1 || { echo "wrk not found. Install it (e.g., brew install wrk) or use --tool ab"; exit 1; }
          run_wrk_batch "$name" "$method" "$url" "$scen" "$batchN" "$batch"
          file="results/raw/${name}_${scen}_n${batchN}_c${C}${KEEP:+_keep}_wrk_b${batch}.txt"
          # Apply scenario-specific non-2xx allowance for this check only
          saved_allow_non2xx="${ALLOW_NON2XX:-0}"
          if (( allow_non2xx_this_scen == 1 )); then ALLOW_NON2XX=${saved_allow_non2xx:-0}; ALLOW_NON2XX=1000000000; fi
          if check_wrk_ok "$file"; then ok=true; fi
          ALLOW_NON2XX="$saved_allow_non2xx"
          if [[ "$ok" == true ]]; then break; fi
        else
          run_ab_batch "$name" "$method" "$url" "$scen" "$batchN" "$batch"
          file="results/raw/${name}_${scen}_n${batchN}_c${C}${KEEP:+_keep}_b${batch}.txt"
          saved_allow_non2xx="${ALLOW_NON2XX:-0}"
          if (( allow_non2xx_this_scen == 1 )); then ALLOW_NON2XX=${saved_allow_non2xx:-0}; ALLOW_NON2XX=1000000000; fi
          if check_ab_ok "$file"; then ok=true; fi
          ALLOW_NON2XX="$saved_allow_non2xx"
          if [[ "$ok" == true ]]; then break; fi
        fi
        echo "Errors detected (batch ${batch} attempt ${attempt}/${MAX_RETRIES}). Retrying in ${RETRY_SLEEP}s..."
        sleep "$RETRY_SLEEP"
      done

      if [[ "$ok" == true ]]; then
        if [[ "$TOOL" == "wrk" ]]; then
          vals=$(parse_wrk_vals "$file")
        else
          vals=$(parse_ab_vals "$file")
        fi
        echo "$vals" >> "$tmpStats"
        echo "$scen,$batch,$name,$vals" >> "$PARTS"
        # Avoid set -e abort on post-increment returning 0
        ((++successCount))
      else
        echo "WARNING: Skipping batch $batch for $name [$scen] after $MAX_RETRIES failed attempts."
      fi

      if (( BATCH_PAUSE > 0  )); then echo "Pausing ${BATCH_PAUSE}s between batches..."; sleep "$BATCH_PAUSE"; fi
    done

    # Aggregate averages across successful batches
    if (( successCount > 0 )); then
      avg_line=$(awk -F, '{a+=$1;b+=$2;c+=$3;d+=$4;e+=$5;f+=$6; n++} END{printf "%.2f,%.3f,%.3f,%.3f,%.3f,%.2f", a/n,b/n,c/n,d/n,e/n,f/n}' "$tmpStats")
      echo "$scen,$name,$avg_line" >> "$SCNCSV"
      echo "$scen,$name,$avg_line" >> "$COMBINED"
    else
      echo "$scen,$name,,,,,," >> "$SCNCSV"
      echo "$scen,$name,,,,,," >> "$COMBINED"
    fi
    rm -f "$tmpStats"
  done
  echo "Wrote $SCNCSV and per-batch $PARTS"

done

echo "Wrote $COMBINED"

if [[ "$SHUTDOWN_AFTER" == true ]]; then
  echo "Stopping servers..."
  ./bin/stop
fi
